---
title: "Qualitative Activity Recognition of Weight Lifting Exercises"
author: "Mariano Fiorentino"
date: "07/07/2016"
output: html_document
---

# Executive Summary
```{r setup, include=FALSE}
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(lubridate)
library(MASS)
library(randomForest)
library(forecast)
library(e1071)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
```

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks.
In this project the goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercises.

### Esploration of the dataset
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. We got the training data for this project here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

And the test data from here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

This dataset is composed by 160 variable. Searching for useful predictors, we choosed to remove from our dataset, variables that had a majority of NA or with a majority of empty value. Other transformation made on the dataset was to remove information about the name of the partecipant, about the date of the test, and variables with zero varibility.


```{r, echo=TRUE} 
set.seed(1234)
if (!"pml-training.csv"  %in% dir()) {
    download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", 
        destfile = "pml-training.csv", method = "curl")
}
#Remove NAs and null values
dataSet <- read.csv("pml-training.csv", na.strings=c("NA","NaN", "", " "))
dataSet <- dataSet[, colSums(is.na(dataSet)) == 0]
#Remove name and dates
dataSet <- dataSet[, -c(1:5)]
#matrix(data = names(dataSet), ncol = 5)
```
To explore the variability and patterns in the dataset we did an svd analisys. As expected the plot shown a significant pattern on the row side, and a minor one on the column side:

```{r, echo=TRUE}
matrixForSdv <- as.matrix(dataSet[,-c(1,55)])
svd1 <- svd(matrixForSdv)
par(mfrow = c(1, 3))
image(t(matrixForSdv)[, nrow(matrixForSdv):1], main = "Original Data")
plot(svd1$u[, 1], ylab = "Row", xlab = "First left singular vector",pch = 19)
plot(svd1$v[, 1], xlab = "Column", ylab = "First right singular vector", pch = 19)
```

###Study design with cross validation
To find the best model to predict the manner in which partecipant did the excercise we splited the dataset in 3 parts:

- the training set (50%), used to build the model
- the test set (25%), used to test the model
- the validation set (25%), used at the end only one time on the choosed model

```{r, echo=TRUE}
inTrain = createDataPartition(dataSet$classe, p = 1/2)[[1]]

training = dataSet[ inTrain,]
testingToSplit = dataSet[-inTrain,]

inTest = createDataPartition(testingToSplit$classe, p = 1/2)[[1]]

testing = testingToSplit[ inTest,]
validation = testingToSplit[-inTest,]

```
###Building the model
We buildt 3 different model:

- **Random Forest**
```{r, echo=TRUE, cache=TRUE}
fitControl <- trainControl(method = "cv",
                           number = 3,
                           allowParallel = TRUE)
x <- training[,-55]
y <- training[,55]

mod1 <- train(x, y, method = "rf", data = training, trControl = fitControl)
pred1 <- predict(mod1, testing[,!names(testing) == 'classe'])
conf1 <- confusionMatrix(pred1, testing$classe)
conf1$table
```

- **Recursive partitioning**

```{r, echo=TRUE, cache=TRUE}
mod2 <- train(classe~., method = "rpart", data = training)
pred2 <- predict(mod2, testing[,!names(testing) == 'classe'])
conf2 <- confusionMatrix(pred2, testing$classe)
conf2$table
```

- **Linear discriminant analysis**

```{r, echo=TRUE, cache=TRUE}
mod3 <- train(classe~., method = "lda", data = training)
pred3 <- predict(mod3, testing[,!names(testing) == 'classe'])
conf3 <- confusionMatrix(pred3, testing$classe)
conf3$table
```

**We choosed the model based on Random Forest because showed the best accuracy rate**

```{r, echo=TRUE}
data.frame("Random Forest" = conf1$overall[1], "Recursive Partitioning" = conf2$overall[1], "Linear Discriminant Analisys" = conf3$overall[1])
```
The model based on Random Forest showed the best accuracy with 29 predictors:
```{r}
plot(mod1, log="y", main="Accuracy Vs Predictors")
```

Testing on the vadidation dataset we got a out of sample error of **0.004%**:

```{r, echo = TRUE}
predFinal <- predict(mod1, validation[,!names(validation) == 'classe'])
confFinal <- confusionMatrix(predFinal, validation$classe)
confFinal$table

data.frame("In Sample Error" = (sum(conf1$table) - sum(diag(conf1$table)))/sum(diag(conf1$table)),
           "Out Of Sample Error" = (sum(confFinal$table) - sum(diag(confFinal$table)))/sum(diag(confFinal$table)))
```
###Predicting on the 20 test cases
To predict the 20 test cases we did on the dataset the same trasformation that we did on the training set.

```{r, echo=TRUE}
if (!"pml-testing.csv"  %in% dir()) {
    download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", 
        destfile = "pml-testing.csv", method = "curl")
}
testCases <- read.csv("pml-testing.csv", na.strings=c("NA","NaN", "", " "))
testCases <- testCases[, colSums(is.na(testCases)) == 0]
testCases <- testCases[, -c(1:5)]
testCases <- testCases[, -c(55)]
levels(testCases$new_window) <- levels(training$new_window)
data.frame(predict(mod1, testCases))
```